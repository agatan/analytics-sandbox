{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df, columns=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_features = df_dummies.drop(['id', 'day', 'month', 'y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_features.values\n",
    "y = df_dummies.y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(clf, X, y, n_splits=10, shuffle=False):\n",
    "    kfold = KFold(n_splits, shuffle=shuffle)\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, y_train = X[train_index], y[train_index]\n",
    "        X_test, y_test = X[test_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.906745300405\n",
      "0.897899004792\n",
      "0.896056026539\n",
      "0.900460829493\n",
      "0.903778801843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.10879285,  0.10730253,  0.32488823,  0.04918033,  0.10134128,\n",
       "        0.01937407,  0.01043219,  0.00298063,  0.00596125,  0.        ,\n",
       "        0.        ,  0.00447094,  0.        ,  0.02235469,  0.00298063,\n",
       "        0.        ,  0.        ,  0.01937407,  0.00149031,  0.00298063,\n",
       "        0.01639344,  0.        ,  0.00596125,  0.05514158,  0.02831595,\n",
       "        0.00596125,  0.05514158,  0.        ,  0.04918033,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgboost.XGBClassifier(n_jobs=4)\n",
    "cross_validation(clf, X, y, n_splits=5)\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efec89e8358>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhIjCn0RkRj5/xvPoQnkGIKRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efeeaa4e438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(clf.feature_importances_[np.argsort(clf.feature_importances_)[::-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905823811279\n",
      "0.898083302617\n",
      "0.895503133063\n",
      "0.901751152074\n",
      "0.905622119816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efec88fe550>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEgJUeiLiJSQ/w/K+aXa0rYCXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efec89345c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_subset = X[:, np.argsort(clf.feature_importances_)[::-1][:8]]\n",
    "subset_clf = xgboost.XGBClassifier(n_jobs=4)\n",
    "cross_validation(subset_clf, X_subset, y, n_splits=5)\n",
    "plt.plot(subset_clf.feature_importances_[np.argsort(subset_clf.feature_importances_)[::-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pprint import pprint\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "def score(params):\n",
    "    print('Training with ...')\n",
    "    pprint(params)\n",
    "    scores = []\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=123)\n",
    "    for train, test in kfold.split(X):\n",
    "        X_train, y_train = X[train], y[train]\n",
    "        X_test, y_test = X[test], y[test]\n",
    "        d_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "        d_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "        watchlist = [(d_train, 'train'), (d_test, 'eval')]\n",
    "        model = xgboost.train(params, d_train, num_boost_round=150,evals=watchlist,early_stopping_rounds=10, verbose_eval=False)\n",
    "        model.predict(d_test)\n",
    "        score = model.best_score\n",
    "        scores.append(score)\n",
    "    avg_score = np.average(scores)\n",
    "    print('Average Score: {}'.format(avg_score))\n",
    "    return { 'loss': avg_score, 'status': STATUS_OK }\n",
    "\n",
    "def optimize(trials):\n",
    "    space = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \n",
    "        #Control complexity of model\n",
    "        \"eta\" : hp.quniform(\"eta\", 0.2, 0.6, 0.05),\n",
    "        \"max_depth\" : hp.choice('max_depth', np.arange(1, 10+1, dtype=int)),\n",
    "        \"min_child_weight\" : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "        'gamma' : hp.quniform('gamma', 0, 1, 0.05),\n",
    "        \n",
    "        #Improve noise robustness \n",
    "        \"subsample\" : hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "        \"colsample_bytree\" : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "        \n",
    "        'num_class' : 3,\n",
    "        'silent' : 1}\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=250)\n",
    "    print('best parameters: {}'.format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "Average Score: 0.23494420000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.35000000000000003,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "Average Score: 0.2319349\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.55,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.30000000000000004,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.2275788\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "Average Score: 0.2338071\n",
      "Training with ...\n",
      "{'colsample_bytree': 1.0,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "Average Score: 0.2326012\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.45,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2263683\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.30000000000000004,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2257466\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.30000000000000004,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2294921\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.05,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2253515\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.5,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.22847699999999996\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.5,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "Average Score: 0.2331821\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.5,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2293272\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.55,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.45,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.2317442\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.6000000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.55,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "Average Score: 0.22645330000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.6000000000000001,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.2287026\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.0,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "Average Score: 0.2310317\n",
      "Training with ...\n",
      "{'colsample_bytree': 1.0,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.55,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.2264417\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "Average Score: 0.2254122\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.15000000000000002,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.2284995\n",
      "Training with ...\n",
      "{'colsample_bytree': 1.0,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.05,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2276986\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 1.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.22576529999999995\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "Average Score: 0.2259804\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "Average Score: 0.23245809999999997\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.2,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.2262305\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.1,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "Average Score: 0.23344550000000003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 1.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22517700000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.22864239999999997\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.4,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.225122\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.4,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.2253078\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 1.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.22547630000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.2,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.22638409999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.4,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.2253151\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.23025820000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2337068\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.35000000000000003,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 1.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.24137370000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.25,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.22561099999999995\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.5,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.22630279999999997\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "Average Score: 0.22570659999999995\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.35000000000000003,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2261149\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.45,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 1.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22794280000000003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2334732\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.55,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.22585889999999997\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "Average Score: 0.23002420000000004\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "Average Score: 0.2362444\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.2258099\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.6000000000000001,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.30000000000000004,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2288007\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.55,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.4,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2301208\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.5,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 1.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2254997\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.22780940000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.25,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.22946470000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 1.0,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22571120000000003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.45,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "Average Score: 0.23838370000000003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "Average Score: 0.2356929\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.55,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.2270587\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.6000000000000001,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 1.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.22636849999999997\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.1,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2286174\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.35000000000000003,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.22860390000000003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.45,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.2262169\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22490860000000001\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.23366779999999995\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.0,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.22709569999999996\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "Average Score: 0.22840280000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.5,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "Average Score: 0.22672119999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.55,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.15000000000000002,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.225998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.25,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.2299562\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.224654\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2244824\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2253194\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.22528209999999999\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.22597589999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2253829\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2270783\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2256618\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22520789999999996\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.2327657\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2286718\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.23327889999999996\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.22580340000000004\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.22531939999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.22753959999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.22627380000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "Average Score: 0.22686960000000003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.233011\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.22539100000000004\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2342136\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.2267098\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.22518349999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 1.0,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.55,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.2258885\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.22993039999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.23354869999999997\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.2268191\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.22539919999999997\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "Average Score: 0.2283485\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2253169\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "Average Score: 0.2257516\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2261333\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2331153\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "Average Score: 0.2322126\n",
      "Training with ...\n",
      "{'colsample_bytree': 1.0,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2292091\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2257752\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.22629380000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.2281889\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.6000000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2263588\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.2335424\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.22656700000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.22848220000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2253145\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "Average Score: 0.2272998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.22531069999999995\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.55,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2332672\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.2272863\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.23846760000000003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.22556290000000004\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.6000000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.30000000000000004,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "Average Score: 0.2288897\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.5,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2259734\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2339729\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22923500000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "Average Score: 0.2259071\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "Average Score: 0.22781559999999995\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.2262186\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.05,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.22557860000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22524469999999996\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 1.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.23596869999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2273307\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2252028\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.23604630000000001\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.55,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.22626649999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.45,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.23334380000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.55,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.23035160000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2256476\n",
      "Training with ...\n",
      "{'colsample_bytree': 1.0,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.5,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "Average Score: 0.2289799\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22772959999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2254883\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "Average Score: 0.2260815\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.4,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.22530479999999997\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.2,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.23309249999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.22657460000000001\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.5,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22747450000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.15000000000000002,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.22625820000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "Average Score: 0.2298593\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.23158900000000004\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.6000000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.2251937\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2335813\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "Average Score: 0.2276589\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.1,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 1.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.22579739999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.35000000000000003,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22496860000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.35000000000000003,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22496860000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.30000000000000004,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2253448\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.4,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2256607\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.25,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.22527709999999995\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.15000000000000002,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.22540700000000005\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.30000000000000004,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.22525889999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.2,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2277526\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.45,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22563450000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.5,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.22533530000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.35000000000000003,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.225631\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.4,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.23128010000000004\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.35000000000000003,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.2252796\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.25,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.22773950000000004\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.05,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.23248599999999997\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.55,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.22563740000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.4,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.23103670000000004\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.45,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22525899999999996\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.25,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.23364539999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.35000000000000003,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.22965050000000004\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.2,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.22527599999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2250859\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.5,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.228411\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2255877\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.30000000000000004,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.23117840000000003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.1,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22698649999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.22712279999999999\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "Average Score: 0.23161610000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2252137\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2260819\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.22961179999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.23335029999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.225163\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.55,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 1.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.2275773\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.2252342\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.15000000000000002,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.22841129999999996\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.22569790000000003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.2,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.22639740000000003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.23050350000000003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.35000000000000003,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.22611340000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.0,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "Average Score: 0.2257692\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.30000000000000004,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.23272179999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.45,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.22560039999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.23367329999999997\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.2289008\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22466979999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2332243\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.22552649999999996\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22668090000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.22778969999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "Average Score: 0.225184\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.22563489999999997\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.22553539999999997\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2301149\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.22494189999999997\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2277447\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.23333949999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "Average Score: 0.2265894\n",
      "Training with ...\n",
      "{'colsample_bytree': 1.0,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.22948980000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.22558660000000003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "Average Score: 0.23338679999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22620579999999996\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.2260262\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.22517810000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.228112\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.225281\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2251509\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.6000000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2284612\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.22548649999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.55,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "Average Score: 0.23308839999999997\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "Average Score: 0.2261587\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.23411850000000003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.22548249999999997\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2282152\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.23314949999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "Average Score: 0.22584680000000001\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2264369\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.22540960000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.22748749999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.22561310000000004\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2256594\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.23464230000000003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22493290000000005\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.22627800000000003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2323429\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.22636499999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 1.0,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22535749999999996\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2318062\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "Average Score: 0.23362750000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.22530140000000004\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.2264199\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.22505680000000003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22607880000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.22812670000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.22624069999999996\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "Average Score: 0.23000600000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.22498269999999998\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "Average Score: 0.2283076\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.6000000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2320128\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "Average Score: 0.2263058\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "Average Score: 0.2339943\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.22574850000000005\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "Average Score: 0.2337125\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "Average Score: 0.22554020000000002\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "Average Score: 0.2252894\n",
      "best parameters: {'colsample_bytree': 0.8, 'eta': 0.2, 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 4.0, 'subsample': 0.8500000000000001}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "optimize(trials)\n",
    "# score(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pprint import pprint\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "def score(params):\n",
    "    print('Training with ...')\n",
    "    pprint(params)\n",
    "    scores = []\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=123)\n",
    "    for train, test in kfold.split(X):\n",
    "        X_train, y_train = X[train], y[train]\n",
    "        X_test, y_test = X[test], y[test]\n",
    "        clf = xgboost.XGBClassifier(**params)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        print(score)\n",
    "        scores.append(score)\n",
    "    avg_score = np.average(scores)\n",
    "    print('Average Score: {}'.format(avg_score))\n",
    "    return { 'loss': -avg_score, 'status': STATUS_OK }\n",
    "\n",
    "def optimize(trials):\n",
    "    space = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \n",
    "        #Control complexity of model\n",
    "        \"eta\" : hp.quniform(\"eta\", 0.2, 0.6, 0.05),\n",
    "        \"max_depth\" : hp.choice('max_depth', np.arange(1, 10+1, dtype=int)),\n",
    "        \"min_child_weight\" : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "        'gamma' : hp.quniform('gamma', 0, 1, 0.05),\n",
    "        \n",
    "        #Improve noise robustness \n",
    "        \"subsample\" : hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "        \"colsample_bytree\" : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "        \n",
    "        'num_class' : 3,\n",
    "        'silent' : 1}\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=250)\n",
    "    print('best parameters: {}'.format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "0.89052709178\n",
      "0.894950239587\n",
      "0.903796535201\n",
      "0.9030593439\n",
      "0.898267600442\n",
      "0.906376704755\n",
      "0.910431256911\n",
      "0.899004791743\n",
      "0.907079646018\n",
      "0.908554572271\n",
      "Average Score: 0.9022047782609027\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.55,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.35000000000000003,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "0.890895687431\n",
      "0.894950239587\n",
      "0.899741983045\n",
      "0.903796535201\n",
      "0.89052709178\n",
      "0.909325469959\n",
      "0.905639513454\n",
      "0.893844452635\n",
      "0.904867256637\n",
      "0.905604719764\n",
      "Average Score: 0.8999192949493698\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.30000000000000004,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "0.890895687431\n",
      "0.894581643937\n",
      "0.902322152599\n",
      "0.901584961297\n",
      "0.895318835238\n",
      "0.905639513454\n",
      "0.910799852562\n",
      "0.897530409141\n",
      "0.902654867257\n",
      "0.908185840708\n",
      "Average Score: 0.9009513763622545\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.1,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "0.890895687431\n",
      "0.896056026539\n",
      "0.90342793955\n",
      "0.904902322153\n",
      "0.895687430888\n",
      "0.902690748249\n",
      "0.910431256911\n",
      "0.89679321784\n",
      "0.902654867257\n",
      "0.908554572271\n",
      "Average Score: 0.9012094069089395\n",
      "Training with ...\n",
      "{'colsample_bytree': 1.0,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.4,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "0.892370070033\n",
      "0.893844452635\n",
      "0.899741983045\n",
      "0.901584961297\n",
      "0.892001474383\n",
      "0.905639513454\n",
      "0.908588278658\n",
      "0.892738665684\n",
      "0.902654867257\n",
      "0.904867256637\n",
      "Average Score: 0.8994031523082894\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "0.892001474383\n",
      "0.895318835238\n",
      "0.898636196093\n",
      "0.902690748249\n",
      "0.893107261334\n",
      "0.906008109104\n",
      "0.907113896056\n",
      "0.890895687431\n",
      "0.903392330383\n",
      "0.904867256637\n",
      "Average Score: 0.8994031794908596\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.0,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "0.893475856985\n",
      "0.897899004792\n",
      "0.898636196093\n",
      "0.904902322153\n",
      "0.895687430888\n",
      "0.905639513454\n",
      "0.906376704755\n",
      "0.893844452635\n",
      "0.903392330383\n",
      "0.906710914454\n",
      "Average Score: 0.9006564726592275\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "0.895318835238\n",
      "0.893107261334\n",
      "0.902322152599\n",
      "0.906008109104\n",
      "0.896424622189\n",
      "0.907851087357\n",
      "0.90969406561\n",
      "0.895687430888\n",
      "0.906342182891\n",
      "0.907448377581\n",
      "Average Score: 0.9020204124791917\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "0.895687430888\n",
      "0.893107261334\n",
      "0.903796535201\n",
      "0.9030593439\n",
      "0.890895687431\n",
      "0.908956874309\n",
      "0.906008109104\n",
      "0.896424622189\n",
      "0.902654867257\n",
      "0.903392330383\n",
      "Average Score: 0.9003983061996917\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.55,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "0.89679321784\n",
      "0.893475856985\n",
      "0.902322152599\n",
      "0.899741983045\n",
      "0.89052709178\n",
      "0.906008109104\n",
      "0.908956874309\n",
      "0.897899004792\n",
      "0.901179941003\n",
      "0.909292035398\n",
      "Average Score: 0.9006196266854554\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "0.895318835238\n",
      "0.895318835238\n",
      "0.901953556948\n",
      "0.906008109104\n",
      "0.895318835238\n",
      "0.906745300405\n",
      "0.910799852562\n",
      "0.902322152599\n",
      "0.905235988201\n",
      "0.907817109145\n",
      "Average Score: 0.9026838574676498\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.2,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "0.894950239587\n",
      "0.894950239587\n",
      "0.898267600442\n",
      "0.903796535201\n",
      "0.893107261334\n",
      "0.904165130851\n",
      "0.906745300405\n",
      "0.892001474383\n",
      "0.90302359882\n",
      "0.906710914454\n",
      "Average Score: 0.8997718295065711\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.6000000000000001,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.30000000000000004,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "0.897161813491\n",
      "0.892738665684\n",
      "0.905639513454\n",
      "0.901216365647\n",
      "0.892738665684\n",
      "0.906376704755\n",
      "0.90969406561\n",
      "0.901584961297\n",
      "0.905973451327\n",
      "0.912610619469\n",
      "Average Score: 0.9025734826417544\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.35000000000000003,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "0.89052709178\n",
      "0.892001474383\n",
      "0.900110578695\n",
      "0.904533726502\n",
      "0.893475856985\n",
      "0.907113896056\n",
      "0.907851087357\n",
      "0.893844452635\n",
      "0.90302359882\n",
      "0.905973451327\n",
      "Average Score: 0.8998455214541152\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.6000000000000001,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.2,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "0.888315517877\n",
      "0.891264283081\n",
      "0.901584961297\n",
      "0.900110578695\n",
      "0.886103943973\n",
      "0.900479174346\n",
      "0.906745300405\n",
      "0.89015849613\n",
      "0.896386430678\n",
      "0.905973451327\n",
      "Average Score: 0.8967122137811282\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.2,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "0.894581643937\n",
      "0.893107261334\n",
      "0.904165130851\n",
      "0.9030593439\n",
      "0.893107261334\n",
      "0.907851087357\n",
      "0.908956874309\n",
      "0.900479174346\n",
      "0.90302359882\n",
      "0.910029498525\n",
      "Average Score: 0.901836087471336\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.45,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "0.889789900479\n",
      "0.892001474383\n",
      "0.899741983045\n",
      "0.900847769996\n",
      "0.885366752672\n",
      "0.901584961297\n",
      "0.906008109104\n",
      "0.889789900479\n",
      "0.896755162242\n",
      "0.905604719764\n",
      "Average Score: 0.8967490733461853\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.05,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "0.892370070033\n",
      "0.895318835238\n",
      "0.902690748249\n",
      "0.901953556948\n",
      "0.896424622189\n",
      "0.904165130851\n",
      "0.90969406561\n",
      "0.897899004792\n",
      "0.905604719764\n",
      "0.908185840708\n",
      "Average Score: 0.9014306594382777\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.55,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "0.891632878732\n",
      "0.893844452635\n",
      "0.900479174346\n",
      "0.899741983045\n",
      "0.889789900479\n",
      "0.905270917803\n",
      "0.909325469959\n",
      "0.894950239587\n",
      "0.907079646018\n",
      "0.907079646018\n",
      "Average Score: 0.8999194308622203\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.889789900479\n",
      "0.892370070033\n",
      "0.900847769996\n",
      "0.898636196093\n",
      "0.885735348323\n",
      "0.900479174346\n",
      "0.907851087357\n",
      "0.89015849613\n",
      "0.896755162242\n",
      "0.905235988201\n",
      "Average Score: 0.8967859193199572\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.5,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "0.895318835238\n",
      "0.893107261334\n",
      "0.905270917803\n",
      "0.902690748249\n",
      "0.891632878732\n",
      "0.906376704755\n",
      "0.911905639513\n",
      "0.896424622189\n",
      "0.905604719764\n",
      "0.911873156342\n",
      "Average Score: 0.9020205483920423\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "0.894950239587\n",
      "0.894213048286\n",
      "0.904902322153\n",
      "0.901216365647\n",
      "0.891264283081\n",
      "0.906008109104\n",
      "0.911905639513\n",
      "0.901584961297\n",
      "0.904867256637\n",
      "0.910766961652\n",
      "Average Score: 0.9021679186958454\n",
      "Training with ...\n",
      "{'colsample_bytree': 1.0,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "0.896056026539\n",
      "0.897530409141\n",
      "0.902690748249\n",
      "0.903796535201\n",
      "0.895687430888\n",
      "0.907113896056\n",
      "0.908219683008\n",
      "0.894213048286\n",
      "0.900073746313\n",
      "0.905973451327\n",
      "Average Score: 0.9011354975008343\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.5,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "0.894581643937\n",
      "0.896056026539\n",
      "0.901584961297\n",
      "0.904902322153\n",
      "0.893107261334\n",
      "0.907113896056\n",
      "0.911905639513\n",
      "0.901953556948\n",
      "0.905235988201\n",
      "0.910029498525\n",
      "Average Score: 0.902647079450303\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "0.893844452635\n",
      "0.895318835238\n",
      "0.901584961297\n",
      "0.903796535201\n",
      "0.892370070033\n",
      "0.906745300405\n",
      "0.910062661261\n",
      "0.901216365647\n",
      "0.905604719764\n",
      "0.909660766962\n",
      "Average Score: 0.902020466844332\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.5,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "0.894950239587\n",
      "0.895687430888\n",
      "0.901953556948\n",
      "0.902690748249\n",
      "0.891632878732\n",
      "0.906008109104\n",
      "0.911537043863\n",
      "0.899741983045\n",
      "0.904867256637\n",
      "0.909292035398\n",
      "Average Score: 0.9018361282451911\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "0.894213048286\n",
      "0.895318835238\n",
      "0.902322152599\n",
      "0.904165130851\n",
      "0.894213048286\n",
      "0.906745300405\n",
      "0.908956874309\n",
      "0.902690748249\n",
      "0.90412979351\n",
      "0.907817109145\n",
      "Average Score: 0.9020572040878235\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 1.0}\n",
      "0.894950239587\n",
      "0.893107261334\n",
      "0.902322152599\n",
      "0.90342793955\n",
      "0.893475856985\n",
      "0.906745300405\n",
      "0.910062661261\n",
      "0.901953556948\n",
      "0.905604719764\n",
      "0.910029498525\n",
      "Average Score: 0.9021679186958454\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "0.898267600442\n",
      "0.892001474383\n",
      "0.900479174346\n",
      "0.901216365647\n",
      "0.890895687431\n",
      "0.9030593439\n",
      "0.908219683008\n",
      "0.900110578695\n",
      "0.902654867257\n",
      "0.907448377581\n",
      "Average Score: 0.9004353152688844\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.55,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 1.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9500000000000001}\n",
      "0.892738665684\n",
      "0.895687430888\n",
      "0.902322152599\n",
      "0.901953556948\n",
      "0.892370070033\n",
      "0.907851087357\n",
      "0.909325469959\n",
      "0.900847769996\n",
      "0.90412979351\n",
      "0.908923303835\n",
      "Average Score: 0.9016149300809932\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.45,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "0.893844452635\n",
      "0.895318835238\n",
      "0.902322152599\n",
      "0.904533726502\n",
      "0.895687430888\n",
      "0.906008109104\n",
      "0.910062661261\n",
      "0.895687430888\n",
      "0.905235988201\n",
      "0.904867256637\n",
      "Average Score: 0.9013568043953126\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "0.891632878732\n",
      "0.896424622189\n",
      "0.904902322153\n",
      "0.904165130851\n",
      "0.897161813491\n",
      "0.908956874309\n",
      "0.912642830815\n",
      "0.900110578695\n",
      "0.905235988201\n",
      "0.911873156342\n",
      "Average Score: 0.9033106195777568\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 1.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "0.89052709178\n",
      "0.896056026539\n",
      "0.90342793955\n",
      "0.902690748249\n",
      "0.895687430888\n",
      "0.907113896056\n",
      "0.911168448212\n",
      "0.897899004792\n",
      "0.907448377581\n",
      "0.909292035398\n",
      "Average Score: 0.9021310999046437\n",
      "Training with ...\n",
      "{'colsample_bytree': 1.0,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "0.89052709178\n",
      "0.896424622189\n",
      "0.9030593439\n",
      "0.902690748249\n",
      "0.896056026539\n",
      "0.905639513454\n",
      "0.910799852562\n",
      "0.89679321784\n",
      "0.904867256637\n",
      "0.910766961652\n",
      "Average Score: 0.9017624634802172\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "0.89015849613\n",
      "0.897161813491\n",
      "0.904533726502\n",
      "0.902322152599\n",
      "0.89679321784\n",
      "0.907482491707\n",
      "0.911537043863\n",
      "0.895687430888\n",
      "0.907079646018\n",
      "0.907079646018\n",
      "Average Score: 0.9019835665054197\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "0.893844452635\n",
      "0.895687430888\n",
      "0.904165130851\n",
      "0.904165130851\n",
      "0.895318835238\n",
      "0.906376704755\n",
      "0.913011426465\n",
      "0.900847769996\n",
      "0.905235988201\n",
      "0.907448377581\n",
      "Average Score: 0.9026101247462506\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "0.892370070033\n",
      "0.893844452635\n",
      "0.906008109104\n",
      "0.901953556948\n",
      "0.89679321784\n",
      "0.906008109104\n",
      "0.911905639513\n",
      "0.899004791743\n",
      "0.905604719764\n",
      "0.908923303835\n",
      "Average Score: 0.9022415970521045\n",
      "Training with ...\n",
      "{'colsample_bytree': 1.0,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "0.892001474383\n",
      "0.896056026539\n",
      "0.899373387394\n",
      "0.901216365647\n",
      "0.896424622189\n",
      "0.904902322153\n",
      "0.913748617766\n",
      "0.896056026539\n",
      "0.903392330383\n",
      "0.904867256637\n",
      "Average Score: 0.9008038429630305\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 1.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "0.894213048286\n",
      "0.893107261334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.902322152599\n",
      "0.900847769996\n",
      "0.892370070033\n",
      "0.906008109104\n",
      "0.905639513454\n",
      "0.893107261334\n",
      "0.903761061947\n",
      "0.902286135693\n",
      "Average Score: 0.899366238378092\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "0.899373387394\n",
      "0.893844452635\n",
      "0.901584961297\n",
      "0.901216365647\n",
      "0.892001474383\n",
      "0.904533726502\n",
      "0.910431256911\n",
      "0.899373387394\n",
      "0.90191740413\n",
      "0.908554572271\n",
      "Average Score: 0.9012830988564836\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.55,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "0.893107261334\n",
      "0.895318835238\n",
      "0.899741983045\n",
      "0.902322152599\n",
      "0.890895687431\n",
      "0.904902322153\n",
      "0.907482491707\n",
      "0.89015849613\n",
      "0.902654867257\n",
      "0.903761061947\n",
      "Average Score: 0.8990345158838629\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.4,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.9}\n",
      "0.892370070033\n",
      "0.893475856985\n",
      "0.900110578695\n",
      "0.903796535201\n",
      "0.892370070033\n",
      "0.906376704755\n",
      "0.911168448212\n",
      "0.898267600442\n",
      "0.90191740413\n",
      "0.905604719764\n",
      "Average Score: 0.9005457988250607\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "0.895318835238\n",
      "0.89679321784\n",
      "0.904533726502\n",
      "0.901953556948\n",
      "0.897530409141\n",
      "0.908588278658\n",
      "0.911537043863\n",
      "0.899741983045\n",
      "0.906342182891\n",
      "0.906342182891\n",
      "Average Score: 0.9028681417016505\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "0.89679321784\n",
      "0.89679321784\n",
      "0.904533726502\n",
      "0.904902322153\n",
      "0.897530409141\n",
      "0.907113896056\n",
      "0.912274235164\n",
      "0.89679321784\n",
      "0.907079646018\n",
      "0.910398230088\n",
      "Average Score: 0.9034212118642134\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.30000000000000004,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "0.892001474383\n",
      "0.896424622189\n",
      "0.904165130851\n",
      "0.9030593439\n",
      "0.897530409141\n",
      "0.907851087357\n",
      "0.911168448212\n",
      "0.897161813491\n",
      "0.908185840708\n",
      "0.907448377581\n",
      "Average Score: 0.9024996547813597\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "0.89679321784\n",
      "0.895687430888\n",
      "0.906008109104\n",
      "0.904165130851\n",
      "0.894950239587\n",
      "0.907482491707\n",
      "0.909325469959\n",
      "0.898267600442\n",
      "0.905604719764\n",
      "0.910398230088\n",
      "Average Score: 0.9028682640232162\n",
      "Training with ...\n",
      "{'colsample_bytree': 1.0,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.15000000000000002,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "0.893107261334\n",
      "0.893475856985\n",
      "0.900847769996\n",
      "0.904165130851\n",
      "0.893844452635\n",
      "0.906376704755\n",
      "0.907113896056\n",
      "0.889421304829\n",
      "0.905973451327\n",
      "0.906710914454\n",
      "Average Score: 0.9001036743223658\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.4,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "0.894950239587\n",
      "0.895318835238\n",
      "0.90342793955\n",
      "0.904165130851\n",
      "0.897899004792\n",
      "0.904533726502\n",
      "0.907482491707\n",
      "0.893475856985\n",
      "0.906342182891\n",
      "0.906710914454\n",
      "Average Score: 0.9014306322557075\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.45,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "0.894581643937\n",
      "0.895687430888\n",
      "0.904902322153\n",
      "0.904902322153\n",
      "0.894213048286\n",
      "0.905270917803\n",
      "0.913748617766\n",
      "0.896424622189\n",
      "0.908554572271\n",
      "0.911135693215\n",
      "Average Score: 0.9029421190661809\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.25,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "0.893475856985\n",
      "0.895318835238\n",
      "0.901584961297\n",
      "0.903796535201\n",
      "0.89679321784\n",
      "0.907482491707\n",
      "0.912274235164\n",
      "0.893844452635\n",
      "0.905973451327\n",
      "0.906710914454\n",
      "Average Score: 0.9017254951848797\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.35000000000000003,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "0.89052709178\n",
      "0.892370070033\n",
      "0.900847769996\n",
      "0.899741983045\n",
      "0.885366752672\n",
      "0.900847769996\n",
      "0.907482491707\n",
      "0.891632878732\n",
      "0.897861356932\n",
      "0.906342182891\n",
      "Average Score: 0.8973020347784674\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "0.896056026539\n",
      "0.891632878732\n",
      "0.903796535201\n",
      "0.90342793955\n",
      "0.895318835238\n",
      "0.905639513454\n",
      "0.910062661261\n",
      "0.900847769996\n",
      "0.905235988201\n",
      "0.910398230088\n",
      "Average Score: 0.9022416378259599\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.55,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "0.892001474383\n",
      "0.89679321784\n",
      "0.900479174346\n",
      "0.90342793955\n",
      "0.890895687431\n",
      "0.908588278658\n",
      "0.910431256911\n",
      "0.890895687431\n",
      "0.90191740413\n",
      "0.905235988201\n",
      "Average Score: 0.9000666108880327\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.4,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "0.894581643937\n",
      "0.892001474383\n",
      "0.906376704755\n",
      "0.906008109104\n",
      "0.896056026539\n",
      "0.907851087357\n",
      "0.910062661261\n",
      "0.899004791743\n",
      "0.905604719764\n",
      "0.908554572271\n",
      "Average Score: 0.902610179111391\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.5,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "0.898636196093\n",
      "0.894213048286\n",
      "0.900847769996\n",
      "0.900479174346\n",
      "0.892370070033\n",
      "0.905639513454\n",
      "0.908956874309\n",
      "0.899741983045\n",
      "0.900442477876\n",
      "0.908185840708\n",
      "Average Score: 0.9009512948145442\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "0.893844452635\n",
      "0.893107261334\n",
      "0.901953556948\n",
      "0.901584961297\n",
      "0.89015849613\n",
      "0.903796535201\n",
      "0.908588278658\n",
      "0.893107261334\n",
      "0.904867256637\n",
      "0.905604719764\n",
      "Average Score: 0.8996612779939698\n",
      "Training with ...\n",
      "{'colsample_bytree': 1.0,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "0.890895687431\n",
      "0.895318835238\n",
      "0.904165130851\n",
      "0.901584961297\n",
      "0.897161813491\n",
      "0.907482491707\n",
      "0.911168448212\n",
      "0.898267600442\n",
      "0.906710914454\n",
      "0.907448377581\n",
      "Average Score: 0.9020204260704767\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.1,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.891632878732\n",
      "0.89679321784\n",
      "0.902322152599\n",
      "0.901216365647\n",
      "0.890895687431\n",
      "0.906008109104\n",
      "0.906745300405\n",
      "0.892370070033\n",
      "0.901548672566\n",
      "0.906710914454\n",
      "Average Score: 0.8996243368812025\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.5,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "0.897899004792\n",
      "0.893844452635\n",
      "0.905639513454\n",
      "0.901216365647\n",
      "0.891632878732\n",
      "0.906745300405\n",
      "0.90969406561\n",
      "0.900847769996\n",
      "0.904498525074\n",
      "0.912241887906\n",
      "Average Score: 0.9024259764251006\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.6000000000000001,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.30000000000000004,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 2.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "0.888684113527\n",
      "0.892001474383\n",
      "0.900479174346\n",
      "0.900110578695\n",
      "0.884998157022\n",
      "0.901953556948\n",
      "0.906008109104\n",
      "0.889421304829\n",
      "0.897123893805\n",
      "0.905235988201\n",
      "Average Score: 0.8966016350859567\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "0.896056026539\n",
      "0.89679321784\n",
      "0.899373387394\n",
      "0.901584961297\n",
      "0.893475856985\n",
      "0.906376704755\n",
      "0.908956874309\n",
      "0.893844452635\n",
      "0.905235988201\n",
      "0.908185840708\n",
      "Average Score: 0.9009883310663069\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.0,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 1.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "0.891632878732\n",
      "0.896424622189\n",
      "0.9030593439\n",
      "0.902690748249\n",
      "0.897899004792\n",
      "0.905270917803\n",
      "0.913011426465\n",
      "0.897530409141\n",
      "0.907448377581\n",
      "0.909660766962\n",
      "Average Score: 0.9024628495814427\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.55,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.45,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 4.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "0.893107261334\n",
      "0.897899004792\n",
      "0.898267600442\n",
      "0.900479174346\n",
      "0.894950239587\n",
      "0.906376704755\n",
      "0.908588278658\n",
      "0.892370070033\n",
      "0.90302359882\n",
      "0.907817109145\n",
      "Average Score: 0.9002879041912261\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 3.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8500000000000001}\n",
      "0.892738665684\n",
      "0.894213048286\n",
      "0.899741983045\n",
      "0.905270917803\n",
      "0.889789900479\n",
      "0.904165130851\n",
      "0.904902322153\n",
      "0.891264283081\n",
      "0.90191740413\n",
      "0.901179941003\n",
      "Average Score: 0.8985183596514977\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9500000000000001,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.35000000000000003,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "0.899373387394\n",
      "0.892738665684\n",
      "0.900847769996\n",
      "0.901584961297\n",
      "0.891632878732\n",
      "0.905639513454\n",
      "0.910431256911\n",
      "0.900110578695\n",
      "0.90191740413\n",
      "0.909292035398\n",
      "Average Score: 0.901356845169168\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.25,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "0.894213048286\n",
      "0.896424622189\n",
      "0.904165130851\n",
      "0.905270917803\n",
      "0.894213048286\n",
      "0.906745300405\n",
      "0.910431256911\n",
      "0.900110578695\n",
      "0.906710914454\n",
      "0.908923303835\n",
      "Average Score: 0.9027208121717025\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.45,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "0.899004791743\n",
      "0.896424622189\n",
      "0.903796535201\n",
      "0.905270917803\n",
      "0.896424622189\n",
      "0.905639513454\n",
      "0.912274235164\n",
      "0.899004791743\n",
      "0.907448377581\n",
      "0.909660766962\n",
      "Average Score: 0.9034949174030424\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.5,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "0.897530409141\n",
      "0.89679321784\n",
      "0.904533726502\n",
      "0.904533726502\n",
      "0.896056026539\n",
      "0.905639513454\n",
      "0.910062661261\n",
      "0.898267600442\n",
      "0.907817109145\n",
      "0.909660766962\n",
      "Average Score: 0.903089475778699\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.6000000000000001,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "0.895687430888\n",
      "0.894213048286\n",
      "0.906376704755\n",
      "0.909325469959\n",
      "0.894213048286\n",
      "0.906745300405\n",
      "0.910799852562\n",
      "0.899004791743\n",
      "0.908185840708\n",
      "0.908185840708\n",
      "Average Score: 0.9032737328301297\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.55,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "0.898267600442\n",
      "0.894213048286\n",
      "0.904165130851\n",
      "0.9030593439\n",
      "0.895687430888\n",
      "0.910062661261\n",
      "0.911168448212\n",
      "0.899373387394\n",
      "0.908554572271\n",
      "0.906710914454\n",
      "Average Score: 0.903126253796046\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.55,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "0.893107261334\n",
      "0.897161813491\n",
      "0.901216365647\n",
      "0.904902322153\n",
      "0.896056026539\n",
      "0.909325469959\n",
      "0.910431256911\n",
      "0.901216365647\n",
      "0.906342182891\n",
      "0.907817109145\n",
      "Average Score: 0.9027576173716193\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.6000000000000001,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.65,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.8}\n",
      "0.897161813491\n",
      "0.89679321784\n",
      "0.90342793955\n",
      "0.905639513454\n",
      "0.893844452635\n",
      "0.904902322153\n",
      "0.910431256911\n",
      "0.897161813491\n",
      "0.905973451327\n",
      "0.907079646018\n",
      "Average Score: 0.9022415426869644\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "0.893475856985\n",
      "0.895687430888\n",
      "0.905639513454\n",
      "0.905270917803\n",
      "0.896424622189\n",
      "0.906008109104\n",
      "0.911905639513\n",
      "0.899741983045\n",
      "0.906342182891\n",
      "0.908554572271\n",
      "Average Score: 0.9029050828144181\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.4,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "0.894581643937\n",
      "0.892738665684\n",
      "0.9030593439\n",
      "0.901953556948\n",
      "0.893844452635\n",
      "0.907851087357\n",
      "0.912642830815\n",
      "0.901216365647\n",
      "0.901548672566\n",
      "0.910029498525\n",
      "Average Score: 0.9019466118013671\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.45,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "0.893475856985\n",
      "0.897899004792\n",
      "0.901953556948\n",
      "0.906376704755\n",
      "0.895687430888\n",
      "0.907113896056\n",
      "0.911905639513\n",
      "0.898267600442\n",
      "0.907817109145\n",
      "0.908923303835\n",
      "Average Score: 0.9029420103359003\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.9,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.25,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.75}\n",
      "0.888684113527\n",
      "0.89052709178\n",
      "0.901953556948\n",
      "0.901216365647\n",
      "0.88389237007\n",
      "0.900479174346\n",
      "0.907113896056\n",
      "0.890895687431\n",
      "0.896755162242\n",
      "0.906342182891\n",
      "Average Score: 0.8967859600938125\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.893475856985\n",
      "0.894213048286\n",
      "0.905639513454\n",
      "0.90342793955\n",
      "0.897899004792\n",
      "0.908219683008\n",
      "0.911537043863\n",
      "0.901953556948\n",
      "0.908185840708\n",
      "0.909292035398\n",
      "Average Score: 0.9033843522991563\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.55,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "0.895687430888\n",
      "0.897161813491\n",
      "0.902322152599\n",
      "0.904902322153\n",
      "0.895318835238\n",
      "0.908956874309\n",
      "0.911537043863\n",
      "0.896056026539\n",
      "0.904867256637\n",
      "0.907448377581\n",
      "Average Score: 0.9024258133296799\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "0.897161813491\n",
      "0.895318835238\n",
      "0.907113896056\n",
      "0.903796535201\n",
      "0.896056026539\n",
      "0.907851087357\n",
      "0.912642830815\n",
      "0.900110578695\n",
      "0.908185840708\n",
      "0.909292035398\n",
      "Average Score: 0.9037529479497277\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.05,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "0.896056026539\n",
      "0.893844452635\n",
      "0.900847769996\n",
      "0.906745300405\n",
      "0.890895687431\n",
      "0.907482491707\n",
      "0.90969406561\n",
      "0.893844452635\n",
      "0.90302359882\n",
      "0.905235988201\n",
      "Average Score: 0.9007669833979735\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "0.893107261334\n",
      "0.897161813491\n",
      "0.904533726502\n",
      "0.907851087357\n",
      "0.89679321784\n",
      "0.904533726502\n",
      "0.908956874309\n",
      "0.897530409141\n",
      "0.905604719764\n",
      "0.909660766962\n",
      "Average Score: 0.9025733603201889\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.15000000000000002,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "0.895687430888\n",
      "0.894213048286\n",
      "0.902690748249\n",
      "0.902322152599\n",
      "0.891632878732\n",
      "0.907113896056\n",
      "0.908588278658\n",
      "0.899741983045\n",
      "0.901548672566\n",
      "0.908185840708\n",
      "Average Score: 0.9011724929787424\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.35000000000000003,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "0.893844452635\n",
      "0.893475856985\n",
      "0.905639513454\n",
      "0.904902322153\n",
      "0.895687430888\n",
      "0.908956874309\n",
      "0.911905639513\n",
      "0.897161813491\n",
      "0.907817109145\n",
      "0.907817109145\n",
      "Average Score: 0.9027208121717024\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.6000000000000001,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.30000000000000004,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "0.893844452635\n",
      "0.896056026539\n",
      "0.900479174346\n",
      "0.902690748249\n",
      "0.892001474383\n",
      "0.907482491707\n",
      "0.906376704755\n",
      "0.893844452635\n",
      "0.905235988201\n",
      "0.907448377581\n",
      "Average Score: 0.9005459891030512\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.5,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "0.896056026539\n",
      "0.896056026539\n",
      "0.903796535201\n",
      "0.905270917803\n",
      "0.896424622189\n",
      "0.906745300405\n",
      "0.911905639513\n",
      "0.900479174346\n",
      "0.906710914454\n",
      "0.910029498525\n",
      "Average Score: 0.9033474655515288\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "0.893844452635\n",
      "0.896056026539\n",
      "0.904902322153\n",
      "0.907482491707\n",
      "0.894950239587\n",
      "0.905639513454\n",
      "0.909325469959\n",
      "0.897530409141\n",
      "0.906710914454\n",
      "0.908923303835\n",
      "Average Score: 0.9025365143464169\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.5,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.55,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "0.891632878732\n",
      "0.895318835238\n",
      "0.901216365647\n",
      "0.901584961297\n",
      "0.893475856985\n",
      "0.909325469959\n",
      "0.912274235164\n",
      "0.898636196093\n",
      "0.904498525074\n",
      "0.907448377581\n",
      "Average Score: 0.9015411701770237\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.2,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.65}\n",
      "0.89679321784\n",
      "0.898267600442\n",
      "0.904533726502\n",
      "0.905270917803\n",
      "0.895318835238\n",
      "0.906376704755\n",
      "0.909325469959\n",
      "0.897161813491\n",
      "0.906710914454\n",
      "0.907817109145\n",
      "Average Score: 0.9027576309629044\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.2,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "0.898267600442\n",
      "0.894950239587\n",
      "0.904165130851\n",
      "0.90342793955\n",
      "0.892738665684\n",
      "0.906376704755\n",
      "0.910062661261\n",
      "0.900110578695\n",
      "0.90412979351\n",
      "0.910029498525\n",
      "Average Score: 0.9024258812861052\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 1,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "0.89015849613\n",
      "0.891264283081\n",
      "0.900847769996\n",
      "0.898636196093\n",
      "0.886472539624\n",
      "0.902322152599\n",
      "0.906745300405\n",
      "0.889421304829\n",
      "0.898230088496\n",
      "0.906342182891\n",
      "Average Score: 0.8970440314143525\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8500000000000001,\n",
      " 'eta': 0.55,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.7000000000000001,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 6.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.7000000000000001}\n",
      "0.893107261334\n",
      "0.898267600442\n",
      "0.903796535201\n",
      "0.904902322153\n",
      "0.899741983045\n",
      "0.905270917803\n",
      "0.910062661261\n",
      "0.897530409141\n",
      "0.904867256637\n",
      "0.907817109145\n",
      "Average Score: 0.9025364056161364\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.8,\n",
      " 'eta': 0.5,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9500000000000001,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 7.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "0.893107261334\n",
      "0.89679321784\n",
      "0.906376704755\n",
      "0.903796535201\n",
      "0.895318835238\n",
      "0.904902322153\n",
      "0.911537043863\n",
      "0.893844452635\n",
      "0.906342182891\n",
      "0.907079646018\n",
      "Average Score: 0.9019098201927352\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.75,\n",
      " 'eta': 0.6000000000000001,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.45,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.6000000000000001}\n",
      "0.89679321784\n",
      "0.894950239587\n",
      "0.900110578695\n",
      "0.904902322153\n",
      "0.892738665684\n",
      "0.906376704755\n",
      "0.906008109104\n",
      "0.893844452635\n",
      "0.904867256637\n",
      "0.907079646018\n",
      "Average Score: 0.9007671193108241\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.7000000000000001,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.6000000000000001,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 5.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "0.897161813491\n",
      "0.895687430888\n",
      "0.905270917803\n",
      "0.90342793955\n",
      "0.896056026539\n",
      "0.908588278658\n",
      "0.910799852562\n",
      "0.895318835238\n",
      "0.905973451327\n",
      "0.908185840708\n",
      "Average Score: 0.9026470386764481\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.45,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 8.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "0.897161813491\n",
      "0.894213048286\n",
      "0.906745300405\n",
      "0.905270917803\n",
      "0.894950239587\n",
      "0.907482491707\n",
      "0.911905639513\n",
      "0.897530409141\n",
      "0.906710914454\n",
      "0.912241887906\n",
      "Average Score: 0.9034212662293536\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.75,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "0.897161813491\n",
      "0.895318835238\n",
      "0.907851087357\n",
      "0.905270917803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896424622189\n",
      "0.907851087357\n",
      "0.911168448212\n",
      "0.901584961297\n",
      "0.906342182891\n",
      "0.910029498525\n",
      "Average Score: 0.9039003454361009\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.6000000000000001,\n",
      " 'eta': 0.35000000000000003,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 1.0,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "0.894950239587\n",
      "0.894581643937\n",
      "0.907113896056\n",
      "0.903796535201\n",
      "0.892370070033\n",
      "0.906376704755\n",
      "0.913748617766\n",
      "0.898267600442\n",
      "0.907079646018\n",
      "0.910398230088\n",
      "Average Score: 0.9028683183883561\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.55,\n",
      " 'eta': 0.4,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "0.898636196093\n",
      "0.890895687431\n",
      "0.906008109104\n",
      "0.904533726502\n",
      "0.893107261334\n",
      "0.908588278658\n",
      "0.910431256911\n",
      "0.897530409141\n",
      "0.905604719764\n",
      "0.910766961652\n",
      "Average Score: 0.9026102606591012\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "0.896424622189\n",
      "0.895318835238\n",
      "0.907851087357\n",
      "0.905270917803\n",
      "0.894950239587\n",
      "0.909325469959\n",
      "0.912274235164\n",
      "0.899373387394\n",
      "0.905973451327\n",
      "0.909660766962\n",
      "Average Score: 0.903642301298131\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.65,\n",
      " 'eta': 0.30000000000000004,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.8500000000000001,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 10.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.5}\n",
      "0.896056026539\n",
      "0.893475856985\n",
      "0.907482491707\n",
      "0.903796535201\n",
      "0.895687430888\n",
      "0.908219683008\n",
      "0.910799852562\n",
      "0.900110578695\n",
      "0.906710914454\n",
      "0.910029498525\n",
      "Average Score: 0.9032368868563575\n",
      "Training with ...\n",
      "{'colsample_bytree': 0.5,\n",
      " 'eta': 0.25,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0.9,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 9.0,\n",
      " 'num_class': 3,\n",
      " 'objective': 'multi:softprob',\n",
      " 'silent': 1,\n",
      " 'subsample': 0.55}\n",
      "0.898267600442\n",
      "0.894213048286\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-ea9c03ac54b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# score(params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-ec5f83820aa0>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(trials)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;34m'num_class'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         'silent' : 1}\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best parameters: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-ec5f83820aa0>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[1;32m    504\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 898\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "optimize(trials)\n",
    "# score(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'colsample_bytree': 0.8, 'eta': 0.2, 'gamma': 0.9, 'max_depth': 3, 'min_child_weight': 4.0, 'subsample': 0.8500000000000001}\n",
    "\n",
    "d = xgboost.DMatrix(X, label=y)\n",
    "\n",
    "watchlist = [(d, 'train')]\n",
    "model = xgboost.train(best_params, d, num_boost_round=150,evals=watchlist,early_stopping_rounds=10, verbose_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"./data/test.csv\")\n",
    "df_test_dummies = pd.get_dummies(df_test, columns=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome'], drop_first=True)\n",
    "df_test_features = df_test_dummies.drop(['id', 'day', 'month'], axis=1)\n",
    "X_test = df_test_features.values\n",
    "predict = model.predict(xgboost.DMatrix(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicts = pd.DataFrame(np.c_[df_test.id.values.astype(np.int64), predict], columns=['id', 'prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_predicts.id  = df_predicts.id.values.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_predicts.to_csv(\"./data/submit.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.618770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.595712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.026217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.024960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.175662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.026513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.006498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.008795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.064689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.166876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.066217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.375431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.301961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.098688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.004347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.201099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.061390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.011756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.091981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.007715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.024925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.007859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>-0.008351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.082001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.006966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.227045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.203646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>-0.002350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>-0.003636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>-0.025497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18053</th>\n",
       "      <td>18054</td>\n",
       "      <td>0.060607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18054</th>\n",
       "      <td>18055</td>\n",
       "      <td>0.011339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18055</th>\n",
       "      <td>18056</td>\n",
       "      <td>0.015911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18056</th>\n",
       "      <td>18057</td>\n",
       "      <td>0.295361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18057</th>\n",
       "      <td>18058</td>\n",
       "      <td>0.067711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18058</th>\n",
       "      <td>18059</td>\n",
       "      <td>0.059234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18059</th>\n",
       "      <td>18060</td>\n",
       "      <td>0.012291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18060</th>\n",
       "      <td>18061</td>\n",
       "      <td>0.027859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18061</th>\n",
       "      <td>18062</td>\n",
       "      <td>-0.006461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18062</th>\n",
       "      <td>18063</td>\n",
       "      <td>-0.001046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18063</th>\n",
       "      <td>18064</td>\n",
       "      <td>0.246929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18064</th>\n",
       "      <td>18065</td>\n",
       "      <td>0.067461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18065</th>\n",
       "      <td>18066</td>\n",
       "      <td>0.196497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18066</th>\n",
       "      <td>18067</td>\n",
       "      <td>0.021504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18067</th>\n",
       "      <td>18068</td>\n",
       "      <td>0.105477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18068</th>\n",
       "      <td>18069</td>\n",
       "      <td>0.012147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18069</th>\n",
       "      <td>18070</td>\n",
       "      <td>0.056421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18070</th>\n",
       "      <td>18071</td>\n",
       "      <td>-0.003727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18071</th>\n",
       "      <td>18072</td>\n",
       "      <td>0.402329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18072</th>\n",
       "      <td>18073</td>\n",
       "      <td>0.262643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18073</th>\n",
       "      <td>18074</td>\n",
       "      <td>0.010050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18074</th>\n",
       "      <td>18075</td>\n",
       "      <td>-0.002947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18075</th>\n",
       "      <td>18076</td>\n",
       "      <td>0.022272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18076</th>\n",
       "      <td>18077</td>\n",
       "      <td>0.047130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18077</th>\n",
       "      <td>18078</td>\n",
       "      <td>0.073164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18078</th>\n",
       "      <td>18079</td>\n",
       "      <td>-0.009412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18079</th>\n",
       "      <td>18080</td>\n",
       "      <td>0.072945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18080</th>\n",
       "      <td>18081</td>\n",
       "      <td>-0.024927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18081</th>\n",
       "      <td>18082</td>\n",
       "      <td>-0.015839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18082</th>\n",
       "      <td>18083</td>\n",
       "      <td>0.005741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18083 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  prediction\n",
       "0          1    0.618770\n",
       "1          2    0.595712\n",
       "2          3   -0.026217\n",
       "3          4   -0.024960\n",
       "4          5    0.175662\n",
       "5          6    0.026513\n",
       "6          7   -0.006498\n",
       "7          8    0.008795\n",
       "8          9    0.064689\n",
       "9         10    0.166876\n",
       "10        11    0.066217\n",
       "11        12    0.375431\n",
       "12        13    0.301961\n",
       "13        14    0.098688\n",
       "14        15   -0.004347\n",
       "15        16    0.201099\n",
       "16        17    0.061390\n",
       "17        18   -0.011756\n",
       "18        19    0.091981\n",
       "19        20    0.007715\n",
       "20        21    0.024925\n",
       "21        22    0.007859\n",
       "22        23   -0.008351\n",
       "23        24    0.082001\n",
       "24        25    0.006966\n",
       "25        26    0.227045\n",
       "26        27    0.203646\n",
       "27        28   -0.002350\n",
       "28        29   -0.003636\n",
       "29        30   -0.025497\n",
       "...      ...         ...\n",
       "18053  18054    0.060607\n",
       "18054  18055    0.011339\n",
       "18055  18056    0.015911\n",
       "18056  18057    0.295361\n",
       "18057  18058    0.067711\n",
       "18058  18059    0.059234\n",
       "18059  18060    0.012291\n",
       "18060  18061    0.027859\n",
       "18061  18062   -0.006461\n",
       "18062  18063   -0.001046\n",
       "18063  18064    0.246929\n",
       "18064  18065    0.067461\n",
       "18065  18066    0.196497\n",
       "18066  18067    0.021504\n",
       "18067  18068    0.105477\n",
       "18068  18069    0.012147\n",
       "18069  18070    0.056421\n",
       "18070  18071   -0.003727\n",
       "18071  18072    0.402329\n",
       "18072  18073    0.262643\n",
       "18073  18074    0.010050\n",
       "18074  18075   -0.002947\n",
       "18075  18076    0.022272\n",
       "18076  18077    0.047130\n",
       "18077  18078    0.073164\n",
       "18078  18079   -0.009412\n",
       "18079  18080    0.072945\n",
       "18080  18081   -0.024927\n",
       "18081  18082   -0.015839\n",
       "18082  18083    0.005741\n",
       "\n",
       "[18083 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/train.csv\")\n",
    "df_dummies = pd.get_dummies(df, columns=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dummies.pdays.where(df.pdays >= 0, 999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
